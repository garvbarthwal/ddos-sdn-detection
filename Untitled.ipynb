{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddb85f65-f8b6-48e0-abde-81d39adca746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import glob\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83958693-b493-46c9-be46-04c8615a1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets',\n",
    "    'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
    "    'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
    "    'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags',\n",
    "    'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Min Packet Length',\n",
    "    'Max Packet Length', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
    "    'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count',\n",
    "    'ECE Flag Count', 'Down/Up Ratio', 'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
    "    'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes',\n",
    "    'Init_Win_bytes_forward', 'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a8853b2-cd28-476e-b8eb-e06aaeb7aeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded D:\\Training\\LDAP-training.parquet with shape: (6715, 78)\n",
      "[INFO] Loaded D:\\Training\\MSSQL-training.parquet with shape: (10974, 78)\n",
      "[INFO] Loaded D:\\Training\\NetBIOS-training.parquet with shape: (1631, 78)\n",
      "[INFO] Loaded D:\\Training\\Portmap-training.parquet with shape: (5105, 78)\n",
      "[INFO] Loaded D:\\Training\\Syn-training.parquet with shape: (70336, 78)\n",
      "[INFO] Loaded D:\\Training\\UDP-training.parquet with shape: (17770, 78)\n",
      "[INFO] Loaded D:\\Training\\UDPLag-training.parquet with shape: (12639, 78)\n",
      "[INFO] Loaded D:\\Testing\\DNS-testing.parquet with shape: (6703, 78)\n",
      "[INFO] Loaded D:\\Testing\\LDAP-testing.parquet with shape: (2831, 78)\n",
      "[INFO] Loaded D:\\Testing\\MSSQL-testing.parquet with shape: (8083, 78)\n",
      "[INFO] Loaded D:\\Testing\\NTP-testing.parquet with shape: (134674, 78)\n",
      "[INFO] Loaded D:\\Testing\\NetBIOS-testing.parquet with shape: (2225, 78)\n",
      "[INFO] Loaded D:\\Testing\\SNMP-testing.parquet with shape: (4018, 78)\n",
      "[INFO] Loaded D:\\Testing\\Syn-testing.parquet with shape: (907, 78)\n",
      "[INFO] Loaded D:\\Testing\\TFTP-testing.parquet with shape: (121833, 78)\n",
      "[INFO] Loaded D:\\Testing\\UDP-testing.parquet with shape: (12462, 78)\n",
      "[INFO] Loaded D:\\Testing\\UDPLag-testing.parquet with shape: (12465, 78)\n",
      "[INFO] Loading training data...\n",
      "[INFO] Loaded D:\\Training\\LDAP-training.parquet with shape: (6715, 78)\n",
      "[INFO] Loaded D:\\Training\\MSSQL-training.parquet with shape: (10974, 78)\n",
      "[INFO] Loaded D:\\Training\\NetBIOS-training.parquet with shape: (1631, 78)\n",
      "[INFO] Loaded D:\\Training\\Portmap-training.parquet with shape: (5105, 78)\n",
      "[INFO] Loaded D:\\Training\\Syn-training.parquet with shape: (70336, 78)\n",
      "[INFO] Loaded D:\\Training\\UDP-training.parquet with shape: (17770, 78)\n",
      "[INFO] Loaded D:\\Training\\UDPLag-training.parquet with shape: (12639, 78)\n",
      "[INFO] Loading test data...\n",
      "[INFO] Loaded D:\\Testing\\DNS-testing.parquet with shape: (6703, 78)\n",
      "[INFO] Loaded D:\\Testing\\LDAP-testing.parquet with shape: (2831, 78)\n",
      "[INFO] Loaded D:\\Testing\\MSSQL-testing.parquet with shape: (8083, 78)\n",
      "[INFO] Loaded D:\\Testing\\NTP-testing.parquet with shape: (134674, 78)\n",
      "[INFO] Loaded D:\\Testing\\NetBIOS-testing.parquet with shape: (2225, 78)\n",
      "[INFO] Loaded D:\\Testing\\SNMP-testing.parquet with shape: (4018, 78)\n",
      "[INFO] Loaded D:\\Testing\\Syn-testing.parquet with shape: (907, 78)\n",
      "[INFO] Loaded D:\\Testing\\TFTP-testing.parquet with shape: (121833, 78)\n",
      "[INFO] Loaded D:\\Testing\\UDP-testing.parquet with shape: (12462, 78)\n",
      "[INFO] Loaded D:\\Testing\\UDPLag-testing.parquet with shape: (12465, 78)\n"
     ]
    }
   ],
   "source": [
    "def load_parquet_files(file_list):\n",
    "    dfs = []\n",
    "    for f in file_list:\n",
    "        df = pd.read_parquet(f)\n",
    "        print(f\"[INFO] Loaded {f} with shape: {df.shape}\")\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# === Load training and test data ===\n",
    "train_files = sorted(glob.glob(r'D:\\Training\\*.parquet'))\n",
    "test_files = sorted(glob.glob(r'D:\\Testing\\*.parquet'))\n",
    "\n",
    "train_df = load_parquet_files(train_files)\n",
    "test_df = load_parquet_files(test_files)\n",
    "print(\"[INFO] Loading training data...\")\n",
    "train_df = load_parquet_files(train_files)\n",
    "\n",
    "print(\"[INFO] Loading test data...\")\n",
    "test_df = load_parquet_files(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b85284e8-ca85-4278-901f-45dbda82159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = train_df.columns.str.strip()\n",
    "test_df.columns = test_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7c4bc06-9ae2-4ac0-aad5-2dcd368aeee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training data shape after filtering: (125170, 41)\n",
      "[INFO] Test data shape after filtering: (306201, 41)\n",
      "[INFO] Using 40 features.\n"
     ]
    }
   ],
   "source": [
    "common_features = [f for f in features if f in train_df.columns and f in test_df.columns]\n",
    "train_df = train_df[common_features + ['Label']]\n",
    "test_df = test_df[common_features + ['Label']]\n",
    "print(f\"[INFO] Training data shape after filtering: {train_df.shape}\")\n",
    "print(f\"[INFO] Test data shape after filtering: {test_df.shape}\")\n",
    "print(f\"[INFO] Using {len(common_features)} features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "594f344b-4618-4372-a58f-762cb8fb6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "test_df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "train_df.fillna(0, inplace=True)\n",
    "test_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d249d93-d1ea-4585-bf55-506b42add53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Binary Label Encoding (Robust) ===\n",
    "train_df['Label'] = train_df['Label'].astype(str).str.strip().str.lower().apply(lambda x: 0 if x == 'benign' else 1)\n",
    "test_df['Label'] = test_df['Label'].astype(str).str.strip().str.lower().apply(lambda x: 0 if x == 'benign' else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abb29fe1-7604-4f80-8945-0ac2e7d13b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_train shape: (125170, 40), y_train shape: (125170,)\n",
      "[INFO] X_test shape: (306201, 40), y_test shape: (306201,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df[common_features].astype(np.float32)\n",
    "y_train = train_df['Label'].astype(np.int32)\n",
    "\n",
    "X_test = test_df[common_features].astype(np.float32)\n",
    "y_test = test_df['Label'].astype(np.int32)\n",
    "\n",
    "print(f\"[INFO] X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"[INFO] X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf4b7871-c8c2-432d-b226-295876891d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Explicit input layer\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fad73ac-12e7-40da-9a92-0ef0d1d3e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "892a78c5-0c08-4f04-8002-8be164831b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting training...\n",
      "Epoch 1/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9760 - loss: 0.0814 - val_accuracy: 0.9942 - val_loss: 0.0195\n",
      "Epoch 2/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0461 - val_accuracy: 0.9942 - val_loss: 0.0204\n",
      "Epoch 3/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0406 - val_accuracy: 0.9962 - val_loss: 0.0114\n",
      "Epoch 4/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0314 - val_accuracy: 0.9975 - val_loss: 0.0097\n",
      "Epoch 5/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0225 - val_accuracy: 0.9985 - val_loss: 0.0061\n",
      "Epoch 6/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0185 - val_accuracy: 0.9965 - val_loss: 0.0130\n",
      "Epoch 7/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0165 - val_accuracy: 0.9818 - val_loss: 0.0354\n",
      "Epoch 8/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0183 - val_accuracy: 0.9977 - val_loss: 0.0055\n",
      "Epoch 9/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0163 - val_accuracy: 0.9877 - val_loss: 0.0228\n",
      "Epoch 10/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9951 - loss: 0.0184 - val_accuracy: 0.9986 - val_loss: 0.0075\n",
      "Epoch 11/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0157 - val_accuracy: 0.9975 - val_loss: 0.0078\n",
      "Epoch 12/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0185 - val_accuracy: 0.9919 - val_loss: 0.0184\n",
      "Epoch 13/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0148 - val_accuracy: 0.9986 - val_loss: 0.0084\n",
      "Epoch 14/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0157 - val_accuracy: 0.9976 - val_loss: 0.0065\n",
      "Epoch 15/15\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0131 - val_accuracy: 0.9954 - val_loss: 0.0102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2dc8f1d5300>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[INFO] Starting training...\")\n",
    "model.fit(X_train_scaled, y_train, epochs=15, batch_size=128, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b09d263d-53e0-41d0-8635-ed2c2fca3bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating model...\n",
      "\u001b[1m9569/9569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 611us/step\n",
      "\n",
      "[RESULT] Confusion Matrix:\n",
      " [[ 51337     67]\n",
      " [ 10660 244137]]\n",
      "\n",
      "[RESULT] Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91     51404\n",
      "           1       1.00      0.96      0.98    254797\n",
      "\n",
      "    accuracy                           0.96    306201\n",
      "   macro avg       0.91      0.98      0.94    306201\n",
      "weighted avg       0.97      0.96      0.97    306201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Evaluating model...\")\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "\n",
    "print(\"\\n[RESULT] Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n[RESULT] Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa6efac3-3c0b-4df6-901b-b8a613c68215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model and scaler saved.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"ddos_detection_model.h5\")\n",
    "model.save(\"ddos_detection_model01.keras\")\n",
    "import joblib\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"[INFO] Model and scaler saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b5fa24-ea66-443e-bc45-4cbdd78e33fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7f0c1-f963-4388-b86a-a2a50b36687d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ddos-env)",
   "language": "python",
   "name": "ddos-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
